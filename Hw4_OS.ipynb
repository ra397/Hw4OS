{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2gWRKnH52IM"
      },
      "source": [
        "# Part - 1\n",
        "# Predicting Laptop Prices with Neural Networks\n",
        "\n",
        "In this exercise, you will learn how to use PyTorch, a powerful machine learning library, to solve computer systems related problems. More specifically, we want to create a neural network that predicts their values based on their specifications. This task will take you through loading and preprocessing data, creating a neural network model, training the model, and evaluating its performance.\n",
        "\n",
        "## Objective\n",
        "\n",
        "- Understand how to handle and preprocess data for a machine learning task.\n",
        "- Learn the basics of PyTorch by creating a simple neural network.\n",
        "- Train the neural network on a dataset of laptop specifications and prices.\n",
        "- Evaluate the model's performance using various metrics.\n",
        "\n",
        "Let's get started by importing the necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjRHfE6J52IO"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25tBbcKD52IO"
      },
      "source": [
        "\n",
        "- Familiarize yourself with the libraries imported above. PyTorch will be used for creating the neural network, pandas for data manipulation, and scikit-learn for data preprocessing and evaluation metrics.\n",
        "# Loading and Inspecting the Dataset\n",
        "\n",
        "The first step in any machine learning task is to understand the data we're working with. We'll load our dataset using pandas and inspect the first few rows to see what our data looks like.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4qBtsIQ52IP"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "dataset_path = 'laptop_data_cleaned.csv'  # Make sure to replace this with the actual path to your dataset\n",
        "df = pd.read_csv(dataset_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhiqUDf-52IP"
      },
      "source": [
        "# Understanding Numerical and Categorical Features\n",
        "\n",
        "When we work with datasets in machine learning, it's important to distinguish between different types of data. Primarily, we deal with two types: numerical and categorical features. Understanding the difference between these two types is crucial for preprocessing data correctly before training a model.\n",
        "\n",
        "## Numerical Features\n",
        "\n",
        "Numerical features are data types that represent quantitative measurements. They are numbers that can be measured or counted. These features can be further divided into two sub-categories:\n",
        "\n",
        "- **Continuous Features**: These are measurements that can take on any value within a range. Examples include height, weight, temperature, and price. The key characteristic of continuous data is that it can be infinitely fine-grained.\n",
        "- **Discrete Features**: These are numeric values that have a finite number of possible values. They often represent counts of objects or occurrences. Examples include the number of bedrooms in a house, the number of pets a person has, or the number of times a customer has made a purchase.\n",
        "\n",
        "## Categorical Features\n",
        "\n",
        "Categorical features, on the other hand, represent qualitative data. These features can take on a limited number of categories or distinct groups. Categorical data cannot be naturally ordered. Examples include colors (red, blue, green), brand names (Nike, Adidas, Puma), and product categories (electronics, furniture, clothing). Categorical features can be further classified as:\n",
        "\n",
        "- **Nominal Features**: These are categories without any inherent order. For example, the brand names of cars or the type of cuisine.\n",
        "- **Ordinal Features**: These are categories that do have a natural order or ranking to them, but the difference between the categories is not uniform. Examples include satisfaction ratings (satisfied, neutral, dissatisfied) and education level (high school, bachelor's, master's).\n",
        "\n",
        "## Why the Distinction Matters\n",
        "\n",
        "The distinction between numerical and categorical features matters because it dictates the type of preprocessing needed before using the data for training a machine learning model. For example:\n",
        "\n",
        "- Numerical data might need to be normalized or standardized to bring all the features to a similar scale.\n",
        "- Categorical data needs to be encoded before it can be used in most machine learning models. Common encoding techniques include one-hot encoding for nominal features and ordinal encoding for ordinal features.\n",
        "\n",
        "Understanding and correctly preprocessing numerical and categorical data can significantly impact the performance of your machine learning model.\n",
        "\n",
        "## Task-1 (5 points):\n",
        "\n",
        "- Look at the output of `df.head()`. Can you identify which columns are numerical and which are categorical?\n",
        "- Identify the target variable we are trying to predict.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWxLeqQI52IP",
        "outputId": "e0e74a22-52da-4b5c-f0a6-c73ded5efd67"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>TypeName</th>\n",
              "      <th>Ram</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Price</th>\n",
              "      <th>TouchScreen</th>\n",
              "      <th>Ips</th>\n",
              "      <th>Ppi</th>\n",
              "      <th>Cpu_brand</th>\n",
              "      <th>HDD</th>\n",
              "      <th>SSD</th>\n",
              "      <th>Gpu_brand</th>\n",
              "      <th>Os</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apple</td>\n",
              "      <td>Ultrabook</td>\n",
              "      <td>8</td>\n",
              "      <td>1.37</td>\n",
              "      <td>11.175755</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>226.983005</td>\n",
              "      <td>Intel Core i5</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>Intel</td>\n",
              "      <td>Mac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Apple</td>\n",
              "      <td>Ultrabook</td>\n",
              "      <td>8</td>\n",
              "      <td>1.34</td>\n",
              "      <td>10.776777</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>127.677940</td>\n",
              "      <td>Intel Core i5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Intel</td>\n",
              "      <td>Mac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HP</td>\n",
              "      <td>Notebook</td>\n",
              "      <td>8</td>\n",
              "      <td>1.86</td>\n",
              "      <td>10.329931</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>141.211998</td>\n",
              "      <td>Intel Core i5</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "      <td>Intel</td>\n",
              "      <td>Others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apple</td>\n",
              "      <td>Ultrabook</td>\n",
              "      <td>16</td>\n",
              "      <td>1.83</td>\n",
              "      <td>11.814476</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>220.534624</td>\n",
              "      <td>Intel Core i7</td>\n",
              "      <td>0</td>\n",
              "      <td>512</td>\n",
              "      <td>AMD</td>\n",
              "      <td>Mac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Apple</td>\n",
              "      <td>Ultrabook</td>\n",
              "      <td>8</td>\n",
              "      <td>1.37</td>\n",
              "      <td>11.473101</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>226.983005</td>\n",
              "      <td>Intel Core i5</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "      <td>Intel</td>\n",
              "      <td>Mac</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Company   TypeName  Ram  Weight      Price  TouchScreen  Ips         Ppi  \\\n",
              "0   Apple  Ultrabook    8    1.37  11.175755            0    1  226.983005   \n",
              "1   Apple  Ultrabook    8    1.34  10.776777            0    0  127.677940   \n",
              "2      HP   Notebook    8    1.86  10.329931            0    0  141.211998   \n",
              "3   Apple  Ultrabook   16    1.83  11.814476            0    1  220.534624   \n",
              "4   Apple  Ultrabook    8    1.37  11.473101            0    1  226.983005   \n",
              "\n",
              "       Cpu_brand  HDD  SSD Gpu_brand      Os  \n",
              "0  Intel Core i5    0  128     Intel     Mac  \n",
              "1  Intel Core i5    0    0     Intel     Mac  \n",
              "2  Intel Core i5    0  256     Intel  Others  \n",
              "3  Intel Core i7    0  512       AMD     Mac  \n",
              "4  Intel Core i5    0  256     Intel     Mac  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Task-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWsfR4SK52IP"
      },
      "source": [
        "# Preprocessing Data for Machine Learning\n",
        "\n",
        "Before we feed our data into a machine learning model, it's crucial to preprocess it. This step ensures that our data is in the right format and is standardized or normalized, making it easier for the model to learn and make accurate predictions. In this notebook, we'll discuss why preprocessing is necessary and go over the mathematics behind the standard scaler and one-hot encoder, two common preprocessing techniques.\n",
        "\n",
        "## Why Preprocess Data?\n",
        "\n",
        "- **Compatibility**: Most machine learning algorithms expect numerical input, so we need to convert categorical data into a numerical format.\n",
        "- **Scale**: Features might be on different scales (e.g., age vs income). Differences in scale can lead to biases where the algorithm disproportionately favors features with larger scales.\n",
        "- **Normalization/Standardization**: This helps to ensure that each feature contributes equally to the prediction.\n",
        "\n",
        "## The Mathematics Behind Preprocessing\n",
        "\n",
        "### Standard Scaler (Standardization)\n",
        "\n",
        "The Standard Scaler standardizes features by removing the mean and scaling to unit variance. This process is also known as \"Z-score normalization\". The formula for calculating the standardized value of a feature is:\n",
        "\n",
        "$$ z = \\frac{x - \\mu}{\\sigma} $$\n",
        "\n",
        "where:\n",
        "- $z$ is the standardized value.\n",
        "- $x$ is the original value of the feature.\n",
        "- $\\mu$ is the mean of the feature values.\n",
        "- $\\sigma$ is the standard deviation of the feature values.\n",
        "\n",
        "### One-Hot Encoder (for Categorical Data)\n",
        "\n",
        "One-Hot Encoding converts categorical variables into a format that can be provided to ML algorithms to do a better job in prediction. For each unique category in a feature, one-hot encoding creates a new column (binary) where 1 indicates the presence of the category and 0 indicates absence. For example, if we have a `Color` feature with three categories ['Red', 'Green', 'Blue'], one-hot encoding it will result in three new columns, one for each category:\n",
        "\n",
        "- Color_Red: [1, 0, 0]\n",
        "- Color_Green: [0, 1, 0]\n",
        "- Color_Blue: [0, 0, 1]\n",
        "\n",
        "This process does not involve complex mathematics but is crucial for handling categorical data.\n",
        "\n",
        "## Applying Preprocessing\n",
        "\n",
        "In our dataset, we use `StandardScaler` for numerical features to standardize them, and `OneHotEncoder` for categorical features to convert them into a numerical format that our machine learning model can work with.\n",
        "\n",
        "```python\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), ['numerical_features_here']),\n",
        "        ('cat', OneHotEncoder(), ['categorical_features_here'])\n",
        "    ])\n",
        "```\n",
        "# Task-2 (5 points):\n",
        "\n",
        "- Put the numrical and cateorical features in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v2TokJg52IP"
      },
      "outputs": [],
      "source": [
        "# Separate target and features\n",
        "X = df.drop('Price', axis=1)\n",
        "y = df['Price']\n",
        "\n",
        "\n",
        "# Task-2\n",
        "# Define preprocessing for numerical and categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # numerical features\n",
        "        ('num', StandardScaler(), ['numerical_column_names_here']),\n",
        "        # categorical features\n",
        "        ('cat', OneHotEncoder(), ['categorical_column_names_here'])\n",
        "    ])\n",
        "\n",
        "# Apply preprocessing\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "y = y.to_numpy().reshape(-1, 1)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.tensor(X_preprocessed.toarray().astype(np.float32))\n",
        "y_tensor = torch.tensor(y.astype(np.float32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_zbD0D052IQ"
      },
      "source": [
        "# Splitting the Dataset\n",
        "\n",
        "It's important to split our dataset into a training set and a testing set. This way, we can train our model on one portion of the data and evaluate its performance on another set that it hasn't seen before, ensuring our model can generalize well to new data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mPsPywh52IQ"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch DataLoader\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNNQyC_352IR"
      },
      "source": [
        "# Creating the Neural Network\n",
        "\n",
        "Now comes the exciting part! We'll define our neural network architecture.\n",
        "\n",
        "## Task-3 (10 points):\n",
        "\n",
        "- Define a neural network class named `LaptopPricePredictor`. This class should inherit from `nn.Module` and define the layers of the network in the `__init__` method. Then, implement the forward pass in the `forward` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lbcEfr852IR"
      },
      "outputs": [],
      "source": [
        "# Task-3\n",
        "class LaptopPricePredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LaptopPricePredictor, self).__init__()\n",
        "        # initialize the layers of the network\n",
        "\n",
        "    def forward(self, x):\n",
        "        # put x through the layer(s) and activation function(s) (like ReLU)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "model = LaptopPricePredictor()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrHsa_0U52IR"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "With our data prepared and our model defined, it's now time to train our model. This involves feeding it the input data, calculating the loss (difference between the model's predictions and the actual prices), and adjusting the model's weights through backpropagation.\n",
        "\n",
        "## Task-4 (20 points):\n",
        "\n",
        "- Complete the training loop below. Fill in the missing parts to calculate the loss, perform backpropagation, and update the model's weights.\n",
        "- Adjust hyperparameters (number of epochs and learning rate) as appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTdZ7wHH52IR",
        "outputId": "a06afc25-855f-4883-d527-04298646c6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Loss: 100.1706\n",
            "Epoch 11/100, Loss: 0.2283\n",
            "Epoch 21/100, Loss: 0.0525\n",
            "Epoch 31/100, Loss: 0.0665\n",
            "Epoch 41/100, Loss: 0.0471\n",
            "Epoch 51/100, Loss: 0.0974\n",
            "Epoch 61/100, Loss: 0.0406\n",
            "Epoch 71/100, Loss: 0.0550\n",
            "Epoch 81/100, Loss: 0.0548\n",
            "Epoch 91/100, Loss: 0.0616\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Task-4\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=100):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for epoch in range(epochs):\n",
        "        for inputs, targets in train_loader:\n",
        "\n",
        "            # Zeroring the gradients strored in optimizer\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Write the forward pass\n",
        "            outputs = ?\n",
        "            # Calculate loss\n",
        "            loss = ?\n",
        "            # Calculate gradients\n",
        "            ?\n",
        "            # Update the model's weights. Tip: step.\n",
        "            ?\n",
        "\n",
        "        if epoch % 10 == 0:  # Print the loss every 10 epochs\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# Call the train_model function\n",
        "?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS0Rew_-52IR"
      },
      "source": [
        "# Evaluating the Model\n",
        "\n",
        "After training the model, it's crucial to evaluate its performance on the test set to see how well it predicts laptop prices on data it hasn't seen before. We'll use several metrics for a comprehensive evaluation.\n",
        "\n",
        "## Task-5 (10 points):\n",
        "\n",
        "- Write the missing code to evaluate the model on the test set. Calculate and print the Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared (R2) score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EySMfvSY52IR",
        "outputId": "70c9fac8-6de9-4de7-9d78-c423c7622595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.0675, RMSE: 0.2599, MAE: 0.1901, R2: 0.8295\n"
          ]
        }
      ],
      "source": [
        "# Task-5\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            # make an inference\n",
        "            outputs = ?\n",
        "            predictions.extend(outputs.view(-1).tolist())\n",
        "            actuals.extend(targets.view(-1).tolist())\n",
        "\n",
        "    mse = mean_squared_error(actuals, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(actuals, predictions)\n",
        "    r2 = r2_score(actuals, predictions)\n",
        "\n",
        "    print(f'MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}')\n",
        "\n",
        "# Call the evaluate_model function\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkajTBtU52IS"
      },
      "source": [
        "# NB: The highest R2 scores and the lowest MSEs get bonus (10) points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rGHKlCo52IS"
      },
      "source": [
        "# Part - 2\n",
        "# Predicting Actual Computer Performance\n",
        "\n",
        "In our Operating Systems (OS) class, we've explored how computers can be monitored by operating systems, from the intricacies of hardware components to the complexities of software operations. We've discussed how an OS is not just the backbone of our computing environments but also a rich source of data that can be analyzed to understand and predict computer performance. Through our discussions and previous homework assignments, we've seen how various metrics and measurements logged by operating systems can offer insights into the efficiency and capability of computers.\n",
        "\n",
        "This assignment takes us a step further into the practical application of what we've learned. We have a dataset, logged by the operating systems of individual computers. It encompasses a variety of attributes that contribute to a computer's performance.\n",
        "\n",
        "Our objective is to predict the Estimated Real Performance (ERP) of these computers, as reported by the OS, leveraging the dataset's attributes. This endeavor will not only reinforce our understanding of the operating system's role in monitoring performance but also enhance our skills in data analysis and machine learning, preparing us for the real-world challenges of optimizing and predicting computer performance.\n",
        "## Dataset Description\n",
        "\n",
        "The dataset contains the following attributes:\n",
        "- **Vendor Name**: The manufacturer of the computer.\n",
        "- **Model Name**: The model of the computer.\n",
        "- **MYCT**: Machine cycle time in nanoseconds, indicating the speed at which the computer operates.\n",
        "- **MMIN**: Minimum main memory in kilobytes, a crucial component for running applications.\n",
        "- **MMAX**: Maximum main memory in kilobytes, defining the upper limit of what the computer can handle in terms of memory.\n",
        "- **CACH**: Cache memory in kilobytes, essential for reducing the average time to access data from the main memory.\n",
        "- **CHMIN**: Minimum channels in units, representing the minimum number of I/O devices the computer can handle.\n",
        "- **CHMAX**: Maximum channels in units, indicating the computer's capability to manage multiple I/O operations.\n",
        "- **PRP**: Performance as Reported by the Producer, offering a benchmark for what we might expect in terms of computer performance.\n",
        "- **ERP**: Estimated Real Performance reported by the OS, the metric we aim to predict to understand the computer's actual performance in real-world operations.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h06HDVMA52IS",
        "outputId": "387979dd-8bca-43a4-db3b-e41fc2073b0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vendor Name</th>\n",
              "      <th>Model Name</th>\n",
              "      <th>MYCT</th>\n",
              "      <th>MMIN</th>\n",
              "      <th>MMAX</th>\n",
              "      <th>CACH</th>\n",
              "      <th>CHMIN</th>\n",
              "      <th>CHMAX</th>\n",
              "      <th>PRP</th>\n",
              "      <th>ERP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adviser</td>\n",
              "      <td>32/60</td>\n",
              "      <td>125</td>\n",
              "      <td>256</td>\n",
              "      <td>6000</td>\n",
              "      <td>256</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amdahl</td>\n",
              "      <td>470v/7</td>\n",
              "      <td>29</td>\n",
              "      <td>8000</td>\n",
              "      <td>32000</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>269</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amdahl</td>\n",
              "      <td>470v/7a</td>\n",
              "      <td>29</td>\n",
              "      <td>8000</td>\n",
              "      <td>32000</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>220</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amdahl</td>\n",
              "      <td>470v/7b</td>\n",
              "      <td>29</td>\n",
              "      <td>8000</td>\n",
              "      <td>32000</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>172</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>amdahl</td>\n",
              "      <td>470v/7c</td>\n",
              "      <td>29</td>\n",
              "      <td>8000</td>\n",
              "      <td>16000</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>132</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Vendor Name Model Name  MYCT  MMIN   MMAX  CACH  CHMIN  CHMAX  PRP  ERP\n",
              "0     adviser      32/60   125   256   6000   256     16    128  198  199\n",
              "1      amdahl     470v/7    29  8000  32000    32      8     32  269  253\n",
              "2      amdahl    470v/7a    29  8000  32000    32      8     32  220  253\n",
              "3      amdahl    470v/7b    29  8000  32000    32      8     32  172  253\n",
              "4      amdahl    470v/7c    29  8000  16000    32      8     16  132  132"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'machine-data.txt'  # Update this path for your file path\n",
        "columns = ['Vendor Name', 'Model Name', 'MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX', 'PRP', 'ERP']\n",
        "data = pd.read_csv(file_path, names=columns)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34dpc4kV52IS"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "- Before we can train our model, we need to preprocess our data. We will standardize the numerical features and encode the categorical features. Since our target, `CACH`, is numerical, we will predict it as is without any encoding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbMlbJGG52IS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Identifying features and target variable\n",
        "X = data.drop('ERP', axis=1)\n",
        "y = data['ERP']\n",
        "\n",
        "# Preprocessing steps\n",
        "categorical_features = ['Vendor Name']\n",
        "numerical_features = ['MYCT', 'MMIN', 'MMAX', 'CHMIN', 'CHMAX', 'PRP', 'CACH']\n",
        "\n",
        "# Create the preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "y = y.ravel()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "# Prepare the data for PyTorch\n",
        "X_train_t = torch.FloatTensor(X_train.toarray())\n",
        "X_test_t = torch.FloatTensor(X_test.toarray())\n",
        "y_train_t = torch.FloatTensor(y_train)\n",
        "y_test_t = torch.FloatTensor(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQLMP5AA52IS"
      },
      "source": [
        "# Building and Training the Neural Network\n",
        "\n",
        "- Now, it's time to build our neural network that will predict the ERP. We'll define a simple architecture in PyTorch, compile the model, and then train it on our preprocessed dataset.\n",
        "\n",
        "# Task-6 (20 points):\n",
        "- Implement the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8wYAJdx52IS"
      },
      "outputs": [],
      "source": [
        "# Task-6\n",
        "# Create the model\n",
        "class PerformancePredictor(nn.Module):\n",
        "?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGxdawep52IT"
      },
      "source": [
        "# Task-7 (30 points):\n",
        "- Train the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTRXmmU252IT",
        "outputId": "b2f544eb-fb56-4364-8558-ceb91ebd4932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 15257.251953125\n",
            "Epoch 100, Loss: 139.0404052734375\n",
            "Epoch 200, Loss: 256.3039245605469\n",
            "Epoch 300, Loss: 229.40573120117188\n",
            "Epoch 400, Loss: 41.3190803527832\n",
            "Epoch 500, Loss: 7.712597846984863\n",
            "Epoch 600, Loss: 5.724462509155273\n",
            "Epoch 700, Loss: 22.129911422729492\n",
            "Epoch 800, Loss: 11.599655151367188\n",
            "Epoch 900, Loss: 4.626453399658203\n",
            "Epoch 1000, Loss: 0.7628453969955444\n",
            "Epoch 1100, Loss: 1.4668089151382446\n",
            "Epoch 1200, Loss: 0.3750244379043579\n",
            "Epoch 1300, Loss: 0.1693851500749588\n",
            "Epoch 1400, Loss: 0.09793586283922195\n"
          ]
        }
      ],
      "source": [
        "# Create dataloaders\n",
        "train_data = TensorDataset(X_train_t, y_train_t)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# Model instantiation\n",
        "model = PerformancePredictor(X_train.shape[1])\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 1500\n",
        "for epoch in range(epochs):\n",
        "    # Task-7\n",
        "    # Train the model\n",
        "    ?\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTUxeVBR52IT"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "- After training our model, let's evaluate its performance on the test set to see how well it predicts the ERP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B98jl08b52IT",
        "outputId": "286ce3ab-73b5-46a3-b7a9-2bed40b366b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 893.9536743164062\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual ERP</th>\n",
              "      <th>Predicted ERP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>102.0</td>\n",
              "      <td>93.120689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.0</td>\n",
              "      <td>21.146931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>24.522631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>919.0</td>\n",
              "      <td>866.111206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34.0</td>\n",
              "      <td>34.104588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>267.0</td>\n",
              "      <td>267.137817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>41.0</td>\n",
              "      <td>41.259495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>19.0</td>\n",
              "      <td>20.663147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1238.0</td>\n",
              "      <td>1058.274658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>227.0</td>\n",
              "      <td>223.221542</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Actual ERP  Predicted ERP\n",
              "0       102.0      93.120689\n",
              "1        25.0      21.146931\n",
              "2        25.0      24.522631\n",
              "3       919.0     866.111206\n",
              "4        34.0      34.104588\n",
              "5       267.0     267.137817\n",
              "6        41.0      41.259495\n",
              "7        19.0      20.663147\n",
              "8      1238.0    1058.274658\n",
              "9       227.0     223.221542"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test_t).squeeze()\n",
        "\n",
        "# Calculate the test loss\n",
        "test_loss = criterion(predictions, y_test_t)\n",
        "print(f'Test Loss: {test_loss.item()}')\n",
        "\n",
        "# Convert predictions and actual values to a pandas DataFrame for easier comparison\n",
        "results_comparison = pd.DataFrame({'Actual ERP': y_test_t.numpy(), 'Predicted ERP': predictions.numpy()})\n",
        "results_comparison = results_comparison.head(10)  # Display the first 10 results for a quick comparison\n",
        "\n",
        "results_comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikat1Xae52IT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}